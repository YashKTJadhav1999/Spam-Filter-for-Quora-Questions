{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Spam Filter for Quora Questions**"
      ],
      "metadata": {
        "id": "Nu7ZUBVVMpk_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GOAL : To build a model for identifying if a Question on Quora is Spam.**"
      ],
      "metadata": {
        "id": "Rdnow49k3o3X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y6X1jK42kwoN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as  tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTizk3lqEPD0",
        "outputId": "b54d9930-4dfb-4a68-e6c2-863a915c157b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTz1BbTzEjzY",
        "outputId": "6ce0fa70-c68b-4f0b-d2fe-3a2b345b47f0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: keras\n",
            "Version: 2.14.0\n",
            "Summary: Deep learning for humans.\n",
            "Home-page: https://keras.io/\n",
            "Author: Keras team\n",
            "Author-email: keras-users@googlegroups.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: \n",
            "Required-by: tensorflow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras==2.14.0     #Installing keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVgbu6OYEvt7",
        "outputId": "ad7439c3-bcaf-4348-ad5d-5b3b2784fbfe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras==2.14.0 in /usr/local/lib/python3.10/dist-packages (2.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**"
      ],
      "metadata": {
        "id": "4ghXvFZL3_1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from tqdm import tqdm  #tracks the time taken to complete the task\n",
        "\n",
        "import math\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation,  Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from tensorflow.compat.v1.keras.layers import CuDNNGRU"
      ],
      "metadata": {
        "id": "nYn44btak2LR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reading the dataset train**"
      ],
      "metadata": {
        "id": "MztxKINzPWEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"/content/train.csv\")\n",
        "print(\"Train shape : \",train_df.shape)"
      ],
      "metadata": {
        "id": "k7I6yRqRk4xc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5070db3a-a70e-442b-baed-aede85a10b96"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape :  (55265, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_types = train_df.groupby('target').agg('count')\n",
        "target_types"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "4O_ZY75oMZyC",
        "outputId": "d9d40b3a-a500-4004-a4e9-7f0b5071d466"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          qid  question_text\n",
              "target                      \n",
              "0.0     51868          51868\n",
              "1.0      3396           3396"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-050b5a93-9b5d-48b4-bc6f-0358c13fe157\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>51868</td>\n",
              "      <td>51868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>3396</td>\n",
              "      <td>3396</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-050b5a93-9b5d-48b4-bc6f-0358c13fe157')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-050b5a93-9b5d-48b4-bc6f-0358c13fe157 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-050b5a93-9b5d-48b4-bc6f-0358c13fe157');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d59e58ae-c71b-40e9-9355-273e135771be\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d59e58ae-c71b-40e9-9355-273e135771be')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d59e58ae-c71b-40e9-9355-273e135771be button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_labels = train_df.target.sort_values().index\n",
        "target_counts = train_df.target.sort_values()"
      ],
      "metadata": {
        "id": "rOUI6KF9M5uL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk  #toolkit build for working with NLP\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXkqeTGFM7xk",
        "outputId": "120ed257-52c8-4eb5-cedd-774551e22305"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stopwords are a set of commonly used words in any language. For eg, in english, 'a', 'the', 'is', 'and', etc.\n",
        "Stopwords are used to eliminate unimportant words, allowing applications to focus on the important words instead."
      ],
      "metadata": {
        "id": "abP4psQWPrHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eng_stopwords = stopwords.words('english')\n",
        "eng_stopwords.remove('not') #remove not from the words as it is negative\n",
        "eng_stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itTtcymHNBOE",
        "outputId": "0f38bd72-e3d4-4514-c844-65d8eef4439e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmetization is a text pre-procesing technique used in NLP models to break a word down to its root meaning to identify similarities. For eg, running becomes run, caring become care, and so on."
      ],
      "metadata": {
        "id": "KtyiN55tQl4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "vKjO3jEtNFVe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_preprocessing(questions):\n",
        "\n",
        "    #data cleaning\n",
        "    questions = re.sub(re.compile('<.*?>'),'',questions)\n",
        "    questions = re.sub('[^A-Za-z0-9]+',' ',questions)\n",
        "\n",
        "    #Lowercase : Converting every word to lowercase.\n",
        "    questions = questions.lower()\n",
        "\n",
        "    #tokenization : Is the process of breaking text into smaller pieces called tokens.\n",
        "    tokens = nltk.word_tokenize(questions)\n",
        "\n",
        "    #stop words removal\n",
        "    questions = [word for word in tokens if word not in eng_stopwords]\n",
        "\n",
        "    #lemmatization\n",
        "    questions = [lemmatizer.lemmatize(word) for word in questions]\n",
        "\n",
        "    #join words in preprocessed questions\n",
        "    questions = ' '.join(questions)\n",
        "\n",
        "    return questions"
      ],
      "metadata": {
        "id": "rISw8Rw2NIJB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['preprocessed_question_text']=train_df[\"question_text\"].apply(lambda question_text: data_preprocessing(question_text))\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0pgorhAZNKnp",
        "outputId": "3e50221a-a330-4a42-bc38-c2e388f9edf3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    qid                                      question_text  \\\n",
              "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
              "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
              "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
              "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
              "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
              "\n",
              "   target                         preprocessed_question_text  \n",
              "0     0.0       quebec nationalist see province nation 1960s  \n",
              "1     0.0  adopted dog would encourage people adopt not shop  \n",
              "2     0.0  velocity affect time velocity affect space geo...  \n",
              "3     0.0        otto von guericke used magdeburg hemisphere  \n",
              "4     0.0  convert montra helicon mountain bike changing ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5de37fe-9903-4d3a-a345-e69d71cfe666\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "      <th>preprocessed_question_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00002165364db923c7e6</td>\n",
              "      <td>How did Quebec nationalists see their province...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>quebec nationalist see province nation 1960s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000032939017120e6e44</td>\n",
              "      <td>Do you have an adopted dog, how would you enco...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>adopted dog would encourage people adopt not shop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000412ca6e4628ce2cf</td>\n",
              "      <td>Why does velocity affect time? Does velocity a...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>velocity affect time velocity affect space geo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000042bf85aa498cd78e</td>\n",
              "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>otto von guericke used magdeburg hemisphere</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000455dfa3e01eae3af</td>\n",
              "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>convert montra helicon mountain bike changing ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5de37fe-9903-4d3a-a345-e69d71cfe666')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f5de37fe-9903-4d3a-a345-e69d71cfe666 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f5de37fe-9903-4d3a-a345-e69d71cfe666');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2aab730a-e460-4531-8edf-ce1a3998c610\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2aab730a-e460-4531-8edf-ce1a3998c610')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2aab730a-e460-4531-8edf-ce1a3998c610 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## split to train and val\n",
        "\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.3, random_state=2018)"
      ],
      "metadata": {
        "id": "h5u_M0nBNPY-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## fill up the missing values in the question_text with \"_na_\"\n",
        "\n",
        "train_df[\"question_text\"] = train_df[\"question_text\"].fillna(\"_na_\").values\n",
        "val_df[\"question_text\"] = val_df[\"question_text\"].fillna(\"_na_\").values"
      ],
      "metadata": {
        "id": "9PR8L6rGNTRW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Get the target values\n",
        "\n",
        "train_y = train_df['target'].values\n",
        "val_y = val_df['target'].values"
      ],
      "metadata": {
        "id": "rL0IjdP2NV8b"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Importing COuntVectorizer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "WWqwXcvnNaMt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CountVectorizer is used to transform a given text into a vector on the basis of frequency(count) of each word that occurs in the entire text.\n",
        "In NLP, models cannot understand textual data, they only accept numbers, so this textual data needs to be vectorized."
      ],
      "metadata": {
        "id": "Wsl2yslyRnVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vect= CountVectorizer(dtype=np.float32,strip_accents='unicode',\n",
        "                      analyzer='word',token_pattern=r'\\w{1,}',\n",
        "                      ngram_range=(1,3), min_df = 3)\n",
        "X_train = vect.fit_transform(list(train_df['preprocessed_question_text'].values))\n",
        "X_val = vect.transform(val_df['preprocessed_question_text'].values)"
      ],
      "metadata": {
        "id": "k7RwCsuqNb5_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Naive Bayes Classifier**\n",
        "- It is a supervised machine learning algorithm, that is used for classfication tasks like text classification.\n",
        "- It is also a part of a family of Generative Learning algorithms, meaning that it seeks to model the distribution of a inputs of a given class or category.\n",
        "- Here we will use three types of Naive Bayes Classifier, Multinomial Naive Bayes, Gaussian Naive Bayes and Bernoulli Naive Bayes Classifier."
      ],
      "metadata": {
        "id": "Kor8KW52TOOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Importing MultinomailNB, GaussianNB and BernoulliNB\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB,GaussianNB,BernoulliNB\n",
        "from sklearn.metrics import accuracy_score,f1_score"
      ],
      "metadata": {
        "id": "Xa1mO6x6NeIu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multinomial Naive Bayes: It is suitable for classification with discrete features (eg word counts for text classification). The multinomai distribution normally requires integer feature counts."
      ],
      "metadata": {
        "id": "X8d_231mShHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf=MultinomialNB()\n",
        "clf.fit(X_train,train_y)"
      ],
      "metadata": {
        "id": "_sd--4GdVha5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Printing the Validation Accuracy and Validation f1_score\n",
        "\n",
        "y_val = clf.predict(X_val)\n",
        "print(\"Validation accuracy: \",accuracy_score(val_y,y_val))\n",
        "print(\"Validation f1_score: \",f1_score(val_y,y_val))"
      ],
      "metadata": {
        "id": "Kwb8BriINi6X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adde837c-3276-430f-9592-7350020a06f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy:  0.9270640598003762\n",
            "Validation f1_score:  0.5412606943931684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del X_train,vect,X_val\n",
        "import gc; gc.collect()\n",
        "time.sleep(10)"
      ],
      "metadata": {
        "id": "kjqx2DXUNlO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Importing TFIDF Vectorizer\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "T1JGggvRNnDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Term Frequency Inverse Document Frequency (TFIDF) shows how important a word is to a document in a collection or corpus. The TFIDF value increases proportionally to the number of times a word apperas in the document and is offset by the number of the documents in the corpus that contains the word."
      ],
      "metadata": {
        "id": "pYz3-iY6UuWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why TFIDF?**\n",
        "- TFIDF is better than CountVectorizer because it not only focuses on the frequency of the word present in the corpus but also provides the importance of words."
      ],
      "metadata": {
        "id": "OuxGM2j2uIom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidfvec= TfidfVectorizer(dtype=np.float32,strip_accents='unicode',\n",
        "                      analyzer='word',token_pattern=r'\\w{1,}',\n",
        "                      ngram_range=(1,3), min_df = 3,\n",
        "                      max_features=None,use_idf=1,smooth_idf=1,sublinear_tf=1,stop_words='english')\n",
        "X_train_tfidf = tfidfvec.fit_transform(list(train_df['preprocessed_question_text'].values) )\n",
        "X_val_tfidf = tfidfvec.transform(val_df['preprocessed_question_text'].values)"
      ],
      "metadata": {
        "id": "1hh31W82NrKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bernoulli Naive Bayes Classifier is based on the Bernoulli Distribution and accepts only binary values, i.e. 0 or 1. It is used when the dataset is in a binary distribution where the output label is either present or absent."
      ],
      "metadata": {
        "id": "xWNnQWhptlbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf=BernoulliNB()\n",
        "clf.fit(X_train_tfidf,train_y)"
      ],
      "metadata": {
        "id": "Y4WLC4o3N9sm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba71c4ef-96af-42b4-cf4f-b2d06a7954c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BernoulliNB()"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Printing the Validation accuracy and Validation f1_score\n",
        "\n",
        "y_val = clf.predict(X_val_tfidf)\n",
        "print(\"Validation accuracy: \",accuracy_score(val_y,y_val))\n",
        "print(\"Validation f1_score: \",f1_score(val_y,y_val))"
      ],
      "metadata": {
        "id": "D2Z87NT4N_6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a44ecea-cc9a-402e-a622-b599cce660b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy:  0.9379461357656372\n",
            "Validation f1_score:  0.5113643214565623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del X_train_tfidf,tfidfvec,X_val_tfidf\n",
        "import gc; gc.collect()\n",
        "time.sleep(10)"
      ],
      "metadata": {
        "id": "PpyDQwkkOB3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Importing HashingVectorizer\n",
        "\n",
        "from sklearn.feature_extraction.text import HashingVectorizer"
      ],
      "metadata": {
        "id": "UQueFTueOEOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hashing Vectorizer is based on feature hashing and is a memory efficient technique, also known as Hashing Trick. The Hashing Vectorizer maintains no vocabulary and determines the index of a word in an array of fixed size via hashing so no worry of mis-spelling."
      ],
      "metadata": {
        "id": "t6XhAvEru0ZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hashvec= HashingVectorizer(dtype=np.float32,strip_accents='unicode',\n",
        "                      analyzer='word',token_pattern=r'\\w{1,}',\n",
        "                      ngram_range=(1,3),n_features = 2**10)\n",
        "X_train_hashvec = hashvec.fit_transform(list(train_df['preprocessed_question_text'].values))\n",
        "X_val_hashvec = hashvec.transform(val_df['preprocessed_question_text'].values)"
      ],
      "metadata": {
        "id": "ZvKMHPIzOGSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Using GaussianNB\n",
        "\n",
        "clf=GaussianNB()\n",
        "clf.fit(X_train_hashvec.toarray(),train_y)"
      ],
      "metadata": {
        "id": "x4XG0iWCOJgp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "425ef855-24f1-4b0d-d6ce-837ab4d86c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gaussian Naive Bayes Classifier is a classification technique used in machine learning based on the probabilistic approach and Gaussian distribution."
      ],
      "metadata": {
        "id": "ra2ve_MOwder"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_val = clf.predict(X_val_hashvec.toarray())\n",
        "print(\"Validation accuracy: \",accuracy_score(val_y,y_val))\n",
        "print(\"Validation f1_score: \",f1_score(val_y,y_val))"
      ],
      "metadata": {
        "id": "8UCN2y7sOLwh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b00ee3f-9646-4058-d81d-13c5abd7ff48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy:  0.7236019058945429\n",
            "Validation f1_score:  0.22872647253615908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf=BernoulliNB()\n",
        "clf.fit(X_train_hashvec,train_y)"
      ],
      "metadata": {
        "id": "YZ9OpjMKOOP5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cf623ee-cc46-4566-ea90-32fa3e64ce06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BernoulliNB()"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val = clf.predict(X_val_hashvec)\n",
        "print(\"Validation accuracy: \",accuracy_score(val_y,y_val))\n",
        "print(\"Validation f1_score: \",f1_score(val_y,y_val))"
      ],
      "metadata": {
        "id": "yIScoTKHOQa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73b6462e-8b32-41ff-8b94-adccf808b09c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy:  0.8969163197962418\n",
            "Validation f1_score:  0.26971614536250227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del X_train_hashvec,hashvec,X_val_hashvec\n",
        "import gc; gc.collect()\n",
        "time.sleep(10)"
      ],
      "metadata": {
        "id": "ypmzhV2pOTU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next steps are as follows:**\n",
        "1. Spliting the training dataset into train and val sample. Cross validation is a time consuming process, so let us do simple train val split.\n",
        "2. Filling up the missing values in the text column with 'NA'.\n",
        "3. Tokenizing the text column and converting them to vector sequence.\n",
        "4. Padding the sequence as needed.\n",
        "  - If the number of words in the text is greater than 'max_len', truncate them to 'max_len'.\n",
        "  - If the number of words in the text is lesser than 'max_len', add zeros for remaining values."
      ],
      "metadata": {
        "id": "_rulmSRjxXqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Embeddings**"
      ],
      "metadata": {
        "id": "2dLcMBZpyjWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## some config values\n",
        "embed_size = 300 # how big is each word vector\n",
        "max_features = 50000 # how many unique words to use (i.e num rows in embedding vector)\n",
        "maxlen = 100 # max number of words in a question to use\n",
        "\n",
        "## Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(train_df[\"question_text\"]))\n",
        "train_X = tokenizer.texts_to_sequences(train_df[\"question_text\"])\n",
        "val_X = tokenizer.texts_to_sequences(val_df[\"question_text\"])\n",
        "\n",
        "## Pad the sentences\n",
        "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
        "val_X = pad_sequences(val_X, maxlen=maxlen)"
      ],
      "metadata": {
        "id": "tPl_fTOvOV15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we are done with all the necessary preprocessing steps, we can first train a Bidirectional GRU model. We will not use any pretrained word embeddings for this model and the embeddings will learn from scratch."
      ],
      "metadata": {
        "id": "UPQ8Biu90O-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Bidirectional GRU model\n",
        "\n",
        "inp = Input(shape=(maxlen,))\n",
        "x = Embedding(max_features, embed_size)(inp)\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.CuDNNGRU(64, return_sequences=True))(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(16, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation=\"sigmoid\")(x)\n",
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "887MAv-oOZMa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ab4fc0-2e05-47ab-b5b2-b06ddd4c8698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, 100)]             0         \n",
            "                                                                 \n",
            " embedding_11 (Embedding)    (None, 100, 300)          15000000  \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 100, 128)         186880    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 128)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                2064      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,188,961\n",
            "Trainable params: 15,188,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gated Recurrent Unit (GRU) is a gating mechanism in Recurrent Neural Networks (RNN) similar to a Long-Short Term Memory (LSTM) unit but without an output gate. GRU's try to solve the vanishing gradient problem that can come with standard recurrent neural network."
      ],
      "metadata": {
        "id": "lzBkJj-DMFss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WHY GRU?**\n",
        "- GRU has fewer gates and fewer parameters than LSTM, which makes it simpler and faster, but also less powerful and adaptable."
      ],
      "metadata": {
        "id": "nG1BsliqLdZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Train the model\n",
        "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
      ],
      "metadata": {
        "id": "EuEeagLtOcNA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e437265c-6637-4075-f44f-4522ab587c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1786/1786 [==============================] - 4462s 2s/step - loss: 0.1278 - accuracy: 0.9503 - val_loss: 0.1115 - val_accuracy: 0.9541\n",
            "Epoch 2/2\n",
            "1786/1786 [==============================] - 4457s 2s/step - loss: 0.0999 - accuracy: 0.9602 - val_loss: 0.1086 - val_accuracy: 0.9566\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb6c20bc7f0>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_noemb_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
        "for thresh in np.arange(0.1, 0.501, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_noemb_val_y>thresh).astype(int))))"
      ],
      "metadata": {
        "id": "zlHikuPcOe-W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0b699eb-b9d3-4c48-bdb7-f1099eabd464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "383/383 [==============================] - 494s 1s/step\n",
            "F1 score at threshold 0.1 is 0.5757985325757158\n",
            "F1 score at threshold 0.11 is 0.5839391330124359\n",
            "F1 score at threshold 0.12 is 0.5915996425379804\n",
            "F1 score at threshold 0.13 is 0.5975710168793742\n",
            "F1 score at threshold 0.14 is 0.6033352294841473\n",
            "F1 score at threshold 0.15 is 0.6083885209713024\n",
            "F1 score at threshold 0.16 is 0.6131122693598527\n",
            "F1 score at threshold 0.17 is 0.6171556002261448\n",
            "F1 score at threshold 0.18 is 0.6204918163418172\n",
            "F1 score at threshold 0.19 is 0.6239513795723083\n",
            "F1 score at threshold 0.2 is 0.6270892049551026\n",
            "F1 score at threshold 0.21 is 0.6303925636982323\n",
            "F1 score at threshold 0.22 is 0.6330881981724247\n",
            "F1 score at threshold 0.23 is 0.6339850341759422\n",
            "F1 score at threshold 0.24 is 0.6356139806093226\n",
            "F1 score at threshold 0.25 is 0.6365603406156208\n",
            "F1 score at threshold 0.26 is 0.6382166955170099\n",
            "F1 score at threshold 0.27 is 0.6399699527829447\n",
            "F1 score at threshold 0.28 is 0.6414316702819957\n",
            "F1 score at threshold 0.29 is 0.6427239147130893\n",
            "F1 score at threshold 0.3 is 0.6429139611891151\n",
            "F1 score at threshold 0.31 is 0.6432096918935089\n",
            "F1 score at threshold 0.32 is 0.6432534440460463\n",
            "F1 score at threshold 0.33 is 0.642645964865432\n",
            "F1 score at threshold 0.34 is 0.6418767830981571\n",
            "F1 score at threshold 0.35 is 0.6413111180317657\n",
            "F1 score at threshold 0.36 is 0.6409979373342499\n",
            "F1 score at threshold 0.37 is 0.6410780558477386\n",
            "F1 score at threshold 0.38 is 0.6401202404809619\n",
            "F1 score at threshold 0.39 is 0.6394805510043085\n",
            "F1 score at threshold 0.4 is 0.6386012214800744\n",
            "F1 score at threshold 0.41 is 0.6376536589390314\n",
            "F1 score at threshold 0.42 is 0.6369148071754485\n",
            "F1 score at threshold 0.43 is 0.6356083710169314\n",
            "F1 score at threshold 0.44 is 0.6340375836076017\n",
            "F1 score at threshold 0.45 is 0.6319061809917886\n",
            "F1 score at threshold 0.46 is 0.6298356893901672\n",
            "F1 score at threshold 0.47 is 0.6263652082558165\n",
            "F1 score at threshold 0.48 is 0.6231306963985488\n",
            "F1 score at threshold 0.49 is 0.6201269670958511\n",
            "F1 score at threshold 0.5 is 0.6157429391945368\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our model building is done, it might be a good idea to clean up some memory before we go to the next step."
      ],
      "metadata": {
        "id": "__wrBYM-NbzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del model, inp, x\n",
        "import gc; gc.collect()\n",
        "time.sleep(10)"
      ],
      "metadata": {
        "id": "syWlSVKsOhj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using GloVe embeddings to rebuild GRU model**\n",
        "- GloVe stands for Global Vectors for word representation.\n",
        "- It is an unsupervised learning algorithm developed to generate word embeddings by aggregating global word co-occurence matrices from a given corpus.\n",
        "- The primary idea behind GloVe word embeddings is to use statistics to derive the link between words."
      ],
      "metadata": {
        "id": "EJrQPiTsxNoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://nlp.stanford.edu/data/glove.840B.300d.zip'"
      ],
      "metadata": {
        "id": "Sit6VlwGOrc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0b15d5b-136d-4bde-e17c-dab997b13c9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-23 10:25:42--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
            "--2023-02-23 10:25:43--  https://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: glove.840B.300d.zip\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  5.07MB/s    in 6m 50s  \n",
            "\n",
            "2023-02-23 10:32:33 (5.06 MB/s) - glove.840B.300d.zip saved [2176768927/2176768927]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we get some baseline GRU model without pre-trained embeddings. Now let us use the provided embeddings and rebuild the model again to see the performance."
      ],
      "metadata": {
        "id": "JP5jmscwO3f1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have four different types of embeddings.\n",
        "1. GoogleNews-vectors-negative300\n",
        "2. glove.8408.300d\n",
        "3. paragram_300_s1999\n",
        "4. wiki-news-300d-1M"
      ],
      "metadata": {
        "id": "nvmL2W0tPK1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip glove.840B.300d.zip"
      ],
      "metadata": {
        "id": "tpv-8pu-PCpf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72f4b9bf-1b01-45d9-d42e-dab5e32b6767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.840B.300d.zip\n",
            "  inflating: glove.840B.300d.txt     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm glove.840B.300d.zip"
      ],
      "metadata": {
        "id": "EH2b7uSNPLyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_FILE = 'glove.840B.300d.txt'\n",
        "def get_coefs(word,*arr):\n",
        "  return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))"
      ],
      "metadata": {
        "id": "MU9HkJSaPN-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "embed_size = all_embs.shape[1]"
      ],
      "metadata": {
        "id": "dun1fUEoPR8R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c341d27-7a0a-41f4-97aa-508f7834f8b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3249: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if (await self.run_code(code, result,  async_=asy)):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del all_embs"
      ],
      "metadata": {
        "id": "Z7lq7itWPT_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "C6CkrJPPPWFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = Input(shape=(maxlen,))\n",
        "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.CuDNNGRU(64, return_sequences=True))(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(16, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation=\"sigmoid\")(x)\n",
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "9D65HoqaPYWz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1de520a4-f448-40e4-9040-ffebe752a641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_14 (InputLayer)       [(None, 100)]             0         \n",
            "                                                                 \n",
            " embedding_13 (Embedding)    (None, 100, 300)          15000000  \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 100, 128)         186880    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 128)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                2064      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,188,961\n",
            "Trainable params: 15,188,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_X, train_y, batch_size=512, epochs=1, validation_data=(val_X, val_y))"
      ],
      "metadata": {
        "id": "jl7pjwYsPbCy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3144af07-4388-4970-970a-a7ad5885fb2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1786/1786 [==============================] - 4592s 3s/step - loss: 0.1156 - accuracy: 0.9545 - val_loss: 0.1028 - val_accuracy: 0.9583\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb6c7b01100>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_glove_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
        "for thresh in np.arange(0.1, 0.501, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_glove_val_y>thresh).astype(int))))"
      ],
      "metadata": {
        "id": "tNKviucMPdWw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0d16cf5-871b-4558-f4ca-2c550acdeb77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "383/383 [==============================] - 523s 1s/step\n",
            "F1 score at threshold 0.1 is 0.5865264487431184\n",
            "F1 score at threshold 0.11 is 0.5954688005400313\n",
            "F1 score at threshold 0.12 is 0.6031107728101797\n",
            "F1 score at threshold 0.13 is 0.6096690175880133\n",
            "F1 score at threshold 0.14 is 0.6160973647752834\n",
            "F1 score at threshold 0.15 is 0.6214168838252228\n",
            "F1 score at threshold 0.16 is 0.6265731253269331\n",
            "F1 score at threshold 0.17 is 0.6308969995941178\n",
            "F1 score at threshold 0.18 is 0.6352061823018941\n",
            "F1 score at threshold 0.19 is 0.6388447653429603\n",
            "F1 score at threshold 0.2 is 0.6424821623027288\n",
            "F1 score at threshold 0.21 is 0.6451039747301922\n",
            "F1 score at threshold 0.22 is 0.6477846046256056\n",
            "F1 score at threshold 0.23 is 0.6501481281982225\n",
            "F1 score at threshold 0.24 is 0.6521887010645896\n",
            "F1 score at threshold 0.25 is 0.6538507832247193\n",
            "F1 score at threshold 0.26 is 0.6546945013720519\n",
            "F1 score at threshold 0.27 is 0.6564748832800926\n",
            "F1 score at threshold 0.28 is 0.6578033042615047\n",
            "F1 score at threshold 0.29 is 0.659257668492072\n",
            "F1 score at threshold 0.3 is 0.6604844540853219\n",
            "F1 score at threshold 0.31 is 0.6618159272024363\n",
            "F1 score at threshold 0.32 is 0.6627181930215019\n",
            "F1 score at threshold 0.33 is 0.6629038247307836\n",
            "F1 score at threshold 0.34 is 0.6633813637130169\n",
            "F1 score at threshold 0.35 is 0.6634649927206036\n",
            "F1 score at threshold 0.36 is 0.6631446444919132\n",
            "F1 score at threshold 0.37 is 0.663805546467543\n",
            "F1 score at threshold 0.38 is 0.6627593300599686\n",
            "F1 score at threshold 0.39 is 0.6626515447790379\n",
            "F1 score at threshold 0.4 is 0.6622887455875682\n",
            "F1 score at threshold 0.41 is 0.6611241497275151\n",
            "F1 score at threshold 0.42 is 0.659776435409099\n",
            "F1 score at threshold 0.43 is 0.6588406735751295\n",
            "F1 score at threshold 0.44 is 0.6580397599706087\n",
            "F1 score at threshold 0.45 is 0.6568498228849163\n",
            "F1 score at threshold 0.46 is 0.6560136314520821\n",
            "F1 score at threshold 0.47 is 0.6547915924474528\n",
            "F1 score at threshold 0.48 is 0.6527237354085603\n",
            "F1 score at threshold 0.49 is 0.6509782168078343\n",
            "F1 score at threshold 0.5 is 0.6481577134986226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del word_index, embeddings_index, embedding_matrix, model, inp, x\n",
        "import gc; gc.collect()\n",
        "time.sleep(10)"
      ],
      "metadata": {
        "id": "aMxyORx4Pf12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using FastText embeddings trained on Wiki News corpus in place of Glove embeddings and rebuilding the model.**"
      ],
      "metadata": {
        "id": "bMPvNtB_xwSQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FastText Embeddings**\n",
        "- FastText is an open source, free library from Facebook AI Research (FAIR) for learning word embeddings and word classification.\n",
        "- This model allows creating supervised and unsupervised learning algorithm for obtaining vector representations for words.\n",
        "- FastText breaks words into several n-grams(sub-words). For instance, the tri-grams for the word apple is app, ppl, and ple (ignoring the starting and ending of boundaries of words). The word embedding vector for apple will be the sum of all these n-grams."
      ],
      "metadata": {
        "id": "STkQHBXrQRAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip'"
      ],
      "metadata": {
        "id": "Axw0mGv5PyMh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a151501-cf5c-48df-f3af-3201dd594e29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-23 12:11:08--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: wiki-news-300d-1M.vec.zip\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M  42.1MB/s    in 14s     \n",
            "\n",
            "2023-02-23 12:11:23 (45.2 MB/s) - wiki-news-300d-1M.vec.zip saved [681808098/681808098]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip wiki-news-300d-1M.vec.zip"
      ],
      "metadata": {
        "id": "wAmJqzr1Pz9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dd1893b-0ff0-4e5b-ce3c-48e94c764a29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  wiki-news-300d-1M.vec.zip\n",
            "  inflating: wiki-news-300d-1M.vec   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm wiki-news-300d-1M.vec.zip"
      ],
      "metadata": {
        "id": "fvO1WTTdP2L2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_FILE2 = 'wiki-news-300d-1M.vec'\n",
        "def get_coefs(word,*arr):\n",
        "  return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index2 = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE2) if len(o)>100)"
      ],
      "metadata": {
        "id": "4D_CS5tTP3-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_embs2 = np.stack(embeddings_index2.values())\n",
        "emb_mean2,emb_std2 = all_embs2.mean(), all_embs2.std()\n",
        "embed_size2 = all_embs2.shape[1]"
      ],
      "metadata": {
        "id": "Axs_vBeoP6Pc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92002561-3cc9-42fa-ee96-3709bf7fec5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3249: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if (await self.run_code(code, result,  async_=asy)):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del all_embs2"
      ],
      "metadata": {
        "id": "gAyR_55qP_vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index2 = tokenizer.word_index\n",
        "nb_words2 = min(max_features, len(word_index2))\n",
        "embedding_matrix2 = np.random.normal(emb_mean2, emb_std2, (nb_words2, embed_size2))\n",
        "for word, i in word_index2.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector2 = embeddings_index2.get(word)\n",
        "    if embedding_vector2 is not None: embedding_matrix2[i] = embedding_vector2"
      ],
      "metadata": {
        "id": "CAWPvbF0QByx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = Input(shape=(maxlen,))\n",
        "x = Embedding(max_features, embed_size2, weights=[embedding_matrix2])(inp)\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(16, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation=\"sigmoid\")(x)\n",
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "epnfmhTZQE-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_X, train_y, batch_size=512, epochs=1, validation_data=(val_X, val_y))"
      ],
      "metadata": {
        "id": "-hfE-JmpQHuu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f4602c1-7ff6-49b3-df84-84d3e04d5820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1786/1786 [==============================] - 4775s 3s/step - loss: 0.1226 - accuracy: 0.9538 - val_loss: 0.1058 - val_accuracy: 0.9579\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb6c24e1910>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_fasttext_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
        "for thresh in np.arange(0.1, 0.501, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_fasttext_val_y>thresh).astype(int))))"
      ],
      "metadata": {
        "id": "LmKNCZQZQKPE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a374038b-44d6-4378-8cd3-6350dbc0d093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "383/383 [==============================] - 524s 1s/step\n",
            "F1 score at threshold 0.1 is 0.59587444978279\n",
            "F1 score at threshold 0.11 is 0.603775812951127\n",
            "F1 score at threshold 0.12 is 0.6108686789375934\n",
            "F1 score at threshold 0.13 is 0.617299181149475\n",
            "F1 score at threshold 0.14 is 0.622688388476538\n",
            "F1 score at threshold 0.15 is 0.6276231057572166\n",
            "F1 score at threshold 0.16 is 0.6319718355771424\n",
            "F1 score at threshold 0.17 is 0.6363982580762672\n",
            "F1 score at threshold 0.18 is 0.6401358485490433\n",
            "F1 score at threshold 0.19 is 0.6441673783091375\n",
            "F1 score at threshold 0.2 is 0.646633740577073\n",
            "F1 score at threshold 0.21 is 0.6486287179127015\n",
            "F1 score at threshold 0.22 is 0.6502250929731846\n",
            "F1 score at threshold 0.23 is 0.6514067371987815\n",
            "F1 score at threshold 0.24 is 0.6526611666788348\n",
            "F1 score at threshold 0.25 is 0.653877400295421\n",
            "F1 score at threshold 0.26 is 0.6546045261035177\n",
            "F1 score at threshold 0.27 is 0.6546622579121398\n",
            "F1 score at threshold 0.28 is 0.6547352721849368\n",
            "F1 score at threshold 0.29 is 0.6546065982489708\n",
            "F1 score at threshold 0.3 is 0.6538040503557744\n",
            "F1 score at threshold 0.31 is 0.6530845918468068\n",
            "F1 score at threshold 0.32 is 0.6525459223359061\n",
            "F1 score at threshold 0.33 is 0.6506839655901847\n",
            "F1 score at threshold 0.34 is 0.6501555541999634\n",
            "F1 score at threshold 0.35 is 0.64840332683027\n",
            "F1 score at threshold 0.36 is 0.647599676220917\n",
            "F1 score at threshold 0.37 is 0.6459572685379137\n",
            "F1 score at threshold 0.38 is 0.6442799746246565\n",
            "F1 score at threshold 0.39 is 0.6432244436383809\n",
            "F1 score at threshold 0.4 is 0.6408511371467953\n",
            "F1 score at threshold 0.41 is 0.6399287374801745\n",
            "F1 score at threshold 0.42 is 0.636499297752809\n",
            "F1 score at threshold 0.43 is 0.6336243186954402\n",
            "F1 score at threshold 0.44 is 0.6302764997543217\n",
            "F1 score at threshold 0.45 is 0.6280961932881066\n",
            "F1 score at threshold 0.46 is 0.6254006501329816\n",
            "F1 score at threshold 0.47 is 0.621896136650235\n",
            "F1 score at threshold 0.48 is 0.6182264299437513\n",
            "F1 score at threshold 0.49 is 0.614805989674586\n",
            "F1 score at threshold 0.5 is 0.6113625648279113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del word_index2, embeddings_index2,  embedding_matrix2, model, inp, x\n",
        "import gc; gc.collect()\n",
        "time.sleep(10)"
      ],
      "metadata": {
        "id": "Ca6MegPoQM3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations:**\n",
        "\n",
        "\n",
        "\n",
        "* Overall pretrained embeddings seem to give better results comapred to non-pretrained model.\n",
        "\n",
        "* The performance of the different pretrained embeddings are almost similar.\n",
        "\n"
      ],
      "metadata": {
        "id": "XHDp3IzSQQP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FINAL BLEND**\n",
        "- Through the results of the models with different pre-trained embeddings are similar, there is a good chance that they might capture different type of information from the data.\n",
        "- So let us do a blend of these two models by averaging their predictions."
      ],
      "metadata": {
        "id": "Yfn0cHxDSKJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_val_y = 0.70*pred_glove_val_y + 0.30*pred_fasttext_val_y\n",
        "for thresh in np.arange(0.1, 0.501, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_val_y>thresh).astype(int))))"
      ],
      "metadata": {
        "id": "-GEv_CrZQlb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aa34d54-63c0-4c16-df50-46ccc1a8b7db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score at threshold 0.1 is 0.5896088087201904\n",
            "F1 score at threshold 0.11 is 0.5987329752405788\n",
            "F1 score at threshold 0.12 is 0.6069245255685933\n",
            "F1 score at threshold 0.13 is 0.6144754531889431\n",
            "F1 score at threshold 0.14 is 0.6201228323699421\n",
            "F1 score at threshold 0.15 is 0.6255799353840971\n",
            "F1 score at threshold 0.16 is 0.6310821755653854\n",
            "F1 score at threshold 0.17 is 0.6355270231807976\n",
            "F1 score at threshold 0.18 is 0.6396636389896332\n",
            "F1 score at threshold 0.19 is 0.6425342309818844\n",
            "F1 score at threshold 0.2 is 0.6459393999307993\n",
            "F1 score at threshold 0.21 is 0.649735696776668\n",
            "F1 score at threshold 0.22 is 0.652322242864381\n",
            "F1 score at threshold 0.23 is 0.6545448331254166\n",
            "F1 score at threshold 0.24 is 0.6553088552915767\n",
            "F1 score at threshold 0.25 is 0.6572896281800391\n",
            "F1 score at threshold 0.26 is 0.6585633016501183\n",
            "F1 score at threshold 0.27 is 0.6601393603716277\n",
            "F1 score at threshold 0.28 is 0.6621043318105486\n",
            "F1 score at threshold 0.29 is 0.6626393882430237\n",
            "F1 score at threshold 0.3 is 0.6638396725603348\n",
            "F1 score at threshold 0.31 is 0.6643959275597\n",
            "F1 score at threshold 0.32 is 0.6643867791578195\n",
            "F1 score at threshold 0.33 is 0.6647198255428083\n",
            "F1 score at threshold 0.34 is 0.6642429345018274\n",
            "F1 score at threshold 0.35 is 0.6638736581975442\n",
            "F1 score at threshold 0.36 is 0.6639373026084922\n",
            "F1 score at threshold 0.37 is 0.6633335957798598\n",
            "F1 score at threshold 0.38 is 0.6625439939551807\n",
            "F1 score at threshold 0.39 is 0.6613178216828803\n",
            "F1 score at threshold 0.4 is 0.6596162807188152\n",
            "F1 score at threshold 0.41 is 0.6594431042237396\n",
            "F1 score at threshold 0.42 is 0.658885153946093\n",
            "F1 score at threshold 0.43 is 0.6571505857383633\n",
            "F1 score at threshold 0.44 is 0.655447372838677\n",
            "F1 score at threshold 0.45 is 0.6534804430232312\n",
            "F1 score at threshold 0.46 is 0.6522212962369384\n",
            "F1 score at threshold 0.47 is 0.6512139851084493\n",
            "F1 score at threshold 0.48 is 0.6483777482404725\n",
            "F1 score at threshold 0.49 is 0.6451314572598759\n",
            "F1 score at threshold 0.5 is 0.6419148888839454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yQ9XLlLlQpra"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}